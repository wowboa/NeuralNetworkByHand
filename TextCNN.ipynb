{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from  torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文本数据\n",
    "def read_data(train_or_test,num=None):\n",
    "    # train数据输入'train',test数据输入'test'\n",
    "    with open(os.path.join('./data',train_or_test+'.txt'),'r',encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    text_all_num = len(lines)\n",
    "    text = []\n",
    "    labels = []\n",
    "    if num and num <= text_all_num :\n",
    "        for i in range(num):\n",
    "            text.append(lines[i].split('\\t')[0])\n",
    "            labels.append(lines[i].split('\\t')[1].strip())\n",
    "        print('已完成{}条数据读取'.format(num))\n",
    "    else:\n",
    "        for line in lines:\n",
    "            text.append(line.split('\\t')[0])\n",
    "            labels.append(line.split('\\t')[1].strip())\n",
    "        print('已完成全部{}条数据读取'.format(text_all_num))\n",
    "    return text,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建词库和随机词向量\n",
    "def built_curpus(text,embedding_num):\n",
    "    word_index_dict = {\"<PAD>\":0,\"<UNK>\":1}\n",
    "    for sentense in text:\n",
    "        for word in sentense:\n",
    "            word_index_dict[word] = word_index_dict.get(word,len(word_index_dict))\n",
    "    return word_index_dict,nn.Embedding(len(word_index_dict),embedding_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已完成全部10000条数据读取\n"
     ]
    }
   ],
   "source": [
    "text,labels = read_data('test')\n",
    "word_index_dict,words_embedding = built_curpus(text,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建Dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self,text,labels,word_index_dict,seq_max_len):\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "        self.word_index_dict = word_index_dict\n",
    "        self.seq_max_len = seq_max_len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sentense = self.text[index][:self.seq_max_len]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        sentense_idx = [self.word_index_dict.get(word) for word in sentense]\n",
    "        sentense_idx = sentense_idx + [0]*(self.seq_max_len - len(sentense_idx))\n",
    "        sentense_idx = torch.tensor(sentense_idx).unsqueeze(dim=0)\n",
    "        return sentense_idx,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 56,  57, 133, 134,  13,  14,  19,  96,  17,  18, 135, 136, 127,  13,\n",
       "          125, 126,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0]]),\n",
       " '3')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TextDataset(text,labels,word_index_dict,100)\n",
    "test_data.__getitem__(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模块\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,kernel_s,embedding_num,seq_max_len,hidden_num):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Conv2d(in_channels=1,out_channels=hidden_num,kernel_size=(kernel_s,embedding_num))\n",
    "        self.act = nn.ReLU()\n",
    "        self.mxp = nn.MaxPool1d(kernel_size=(seq_max_len-kernel_s+1))\n",
    "    \n",
    "    def forward(self,batch_emb):\n",
    "        c = self.cnn.forward(batch_emb)\n",
    "        a = self.act.forward(c)\n",
    "        a = a.squeeze(dim=-1)\n",
    "        m = self.mxp.forward(a)\n",
    "        m = m.squeeze(dim=-1)\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建TextCNN网络结构\n",
    "class TextCNNModel(nn.Module):\n",
    "    def __init__(self,embedding_matrix,seq_max_len,class_num,hidden_num):\n",
    "        super().__init__()\n",
    "        self.embedding_num = embedding_matrix.weight.shape[1]\n",
    "\n",
    "        self.block1 = Block(2,self.embedding_num,seq_max_len,class_num,hidden_num)\n",
    "        self.block2 = Block(3,self.embedding_num,seq_max_len,class_num,hidden_num)\n",
    "        self.block3 = Block(4,self.embedding_num,seq_max_len,class_num,hidden_num)\n",
    "        self.block4 = Block(5,self.embedding_num,seq_max_len,class_num,hidden_num)\n",
    "\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_num*4,class_num)\n",
    "        self.loss_fun = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self,batch_idx,batch_label=None):\n",
    "        batch_emb = self.embedding_matrix(batch_idx)\n",
    "        b1_result = self.block1.forward(batch_emb)\n",
    "        b2_result = self.block1.forward(batch_emb)\n",
    "        b3_result = self.block1.forward(batch_emb)\n",
    "        b4_result = self.block1.forward(batch_emb)\n",
    "\n",
    "        feature = torch.cat([b1_result,b2_result,b3_result,b4_result],dim=1)\n",
    "        pre = self.classifier(feature)\n",
    "        \n",
    "        if batch_label is not None:\n",
    "            loss = self.loss_fun(pre,batch_label)\n",
    "            return loss\n",
    "        else:\n",
    "            return torch.argmax(pre,dim=-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
